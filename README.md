# Rick and Morty Backend API

## Краткое описание проекта

Backend-сервис для приложения по просмотру персонажей мультсериала "Рик и Морти". Приложение предоставляет REST API для получения информации о персонажах из официального Rick and Morty API, а также генерирует уникальные кинематографические предыстории персонажей с использованием искусственного интеллекта через Hugging Face Inference API.

### Основные возможности:
- Получение списка персонажей с пагинацией и поиском по имени
- Получение детальной информации о конкретном персонаже
- AI-генерация уникальных предысторий для каждого персонажа

## Инструкции по установке и запуску

### Требования
- Python 3.11+
- Hugging Face API токен

### Установка

1. Клонируйте репозиторий:
```bash
git clone <repository-url>
cd ricky-morty-backend
```

2. Создайте и активируйте виртуальное окружение:
```bash
# Windows
python -m venv .venv
.venv\Scripts\activate

# Linux/macOS
python -m venv .venv
source .venv/bin/activate
```

3. Установите зависимости:
```bash
pip install -r requirements.txt
```

4. Создайте файл `.env` на основе примера:
```bash
cp .env.example .env
```

5. Добавьте ваш Hugging Face API токен в файл `.env`:
```
HF_TOKEN=your_api_token_here
```

### Запуск

```bash
uvicorn main:app --reload
```

Сервер будет доступен по адресу: `http://localhost:8000`

### API Endpoints

| Метод | Endpoint | Описание |
|-------|----------|----------|
| GET | `/api/characters` | Список персонажей (параметры: `page`, `name`) |
| GET | `/api/characters/{id}` | Информация о персонаже |
| GET | `/api/ai/character-description/{id}` | AI-генерация предыстории персонажа |

## Описание процесса проектирования и разработки

### Архитектура

Проект построен по принципу модульной архитектуры с разделением ответственности:

```
ricky-morty-backend/
├── main.py              # Точка входа, определение API endpoints
├── core/
│   ├── settings.py      # Конфигурация приложения через pydantic-settings
│   └── hf_client.py     # Клиент для работы с Hugging Face API
├── requirements.txt     # Зависимости проекта
└── .env                 # Переменные окружения (не в git)
```

### Этапы разработки

1. **Проектирование API** - Определение endpoints для работы с персонажами и AI-функциональностью
2. **Настройка конфигурации** - Реализация безопасного хранения секретов через переменные окружения
3. **Интеграция с Rick and Morty API** - Proxy-слой для получения данных о персонажах
4. **Интеграция с Hugging Face** - Подключение AI-модели для генерации текста
5. **Настройка CORS** - Конфигурация для работы с frontend-приложением

## Уникальные подходы и методологии

### Прокси-архитектура для внешнего API
Вместо прямых запросов с frontend к Rick and Morty API, backend выступает промежуточным слоем. Это позволяет:
- Контролировать и логировать все запросы
- Добавлять дополнительную логику обработки
- Скрывать детали внешнего API от клиента
- При необходимости кэшировать ответы

### Асинхронная обработка запросов
Использование `httpx.AsyncClient` для неблокирующих HTTP-запросов к внешнему API, что обеспечивает высокую производительность при большом количестве одновременных запросов.

### Типобезопасная конфигурация
Применение `pydantic-settings` для валидации переменных окружения с автоматической загрузкой из `.env` файла и проверкой типов.

### AI-интеграция
Использование Hugging Face Inference API позволяет избежать необходимости развертывания собственных ML-моделей, снижая требования к инфраструктуре и упрощая масштабирование.

## Компромиссы, принятые во время разработки

### 1. Синхронный HTTP-клиент для AI-запросов
**Решение:** Использование `requests` вместо асинхронного `httpx` в `hf_client.py`.

**Причина:** Упрощение кода и отладки при интеграции с Hugging Face API.

**Недостаток:** Блокирующие вызовы могут снизить throughput при высокой нагрузке.

**Альтернатива:** Миграция на `httpx.AsyncClient` или вынос AI-вызовов в background tasks.

### 2. Модель BART-large-CNN
**Решение:** Использование модели `facebook/bart-large-cnn` для генерации текста.

**Причина:** Доступность модели и простота интеграции через Inference API.

**Недостаток:** BART-CNN оптимизирована для суммаризации, а не для креативной генерации текста. Результаты могут быть менее качественными для создания художественных предысторий.

**Альтернатива:** Использование LLM-моделей (Mistral, Llama) или GPT через OpenAI API.

### 3. Отсутствие кэширования
**Решение:** Каждый запрос к внешним API выполняется заново.

**Причина:** Простота реализации для MVP.

**Недостаток:** Повышенная нагрузка на внешние API и увеличенное время ответа.

**Альтернатива:** Добавление Redis или in-memory кэширования.

### 4. Ограниченный CORS
**Решение:** CORS настроен только для конкретного frontend-домена на Vercel.

**Причина:** Безопасность - предотвращение несанкционированного доступа.

**Недостаток:** Требует обновления при изменении домена frontend.

### 5. Отсутствие базы данных
**Решение:** Stateless архитектура без персистентного хранения.

**Причина:** Все данные получаются из внешних источников, собственное хранение не требуется для текущего функционала.

**Недостаток:** Невозможность сохранения сгенерированных предысторий для повторного использования.

## Известные ошибки и проблемы

### 1. Некорректный выбор модели для генерации текста
Модель `facebook/bart-large-cnn` предназначена для суммаризации текста, а не для генеративных задач. Промпт в формате `[INST]...[/INST]` не соответствует формату этой модели, что может приводить к неожиданным результатам генерации.

**Рекомендация:** Заменить на модель, предназначенную для генерации текста (например, `mistralai/Mistral-7B-Instruct`).

### 2. Смешение синхронного и асинхронного кода
В endpoint `/api/ai/character-description/{char_id}` используется асинхронный `httpx` для получения данных персонажа, но синхронный `requests` для вызова Hugging Face API. Это неоптимально и может вызывать блокировку event loop.

### 3. Отсутствие обработки ошибок от внешних API
При недоступности Rick and Morty API или Hugging Face API, ошибки будут проброшены напрямую клиенту без форматирования.

### 4. Нет валидации входных параметров
Параметры `page` и `name` не валидируются перед отправкой во внешний API.

### 5. Timeout для AI-запросов
Установлен timeout 120 секунд для запросов к Hugging Face. При холодном старте модели это может быть недостаточно.

## Выбор технического стека

### FastAPI
- **Почему:** Современный, быстрый веб-фреймворк с автоматической документацией OpenAPI
- **Преимущества:** Нативная поддержка async/await, автоматическая валидация через Pydantic, интерактивная документация Swagger UI
- **Альтернативы:** Flask (менее производительный), Django (избыточен для API)

### Pydantic + pydantic-settings
- **Почему:** Типобезопасная валидация данных и конфигурации
- **Преимущества:** Автоматическая загрузка `.env`, валидация типов, интеграция с FastAPI
- **Альтернативы:** python-dotenv (меньше возможностей)

### httpx
- **Почему:** Современный HTTP-клиент с поддержкой async
- **Преимущества:** API совместим с requests, полная поддержка HTTP/2, асинхронность
- **Альтернативы:** aiohttp (более сложный API), requests (только синхронный)

### Hugging Face Inference API
- **Почему:** Serverless доступ к ML-моделям без необходимости развертывания
- **Преимущества:** Простота интеграции, масштабируемость, отсутствие затрат на инфраструктуру
- **Альтернативы:** OpenAI API (платный), self-hosted модели (требуют GPU)

### Uvicorn
- **Почему:** ASGI-сервер, рекомендованный для FastAPI
- **Преимущества:** Высокая производительность, поддержка hot-reload
- **Альтернативы:** Gunicorn с Uvicorn workers (для production)

---

## Лицензия

MIT License
